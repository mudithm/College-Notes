<h1>Lecture 2</h1>

---

<h3>Review: P &#x225F; NP</h3>

  * __F2.1__
      - &#x2227;=And
      - &#x2228;=Or
      - &#772;=Not X
      - If there exists an assignment algorithm (assigns each variable to T or F to get a true statement)
          + If there is some ALG' that takes a predicate and tells us that if an assignment exists, then an algorithm that finds the satisfying assignment efficiently must exist.
          + If we "torture" ALG', we can find the correct assignment for the predicate
              * If we pass the value `(X&#772; &#x2227;   &Phi;)` into ALG', then 
                  - The output is only Yes if both the first and second terms can be assigned a value that lets them be true (ie, X&#772; is true and an assignment for  &Phi; exists such that X is false)
                  - If an assignment still exists, then X&#772; is true and therefore X is false
                  - If an assigment does not exist, then X&#772; is false and therefore X is true
                  - You can do this for all the variables in the predicate to find the value, keeping each prior variable to the value that is the result of its iteration of this algorithm
                      + once you know for sure the value of a variable, you also know that there exists a predicate with that assignment; so, as long as you set the variable to the value produced by tha alg for each further iteration, you can eventually find a solution.
                          * Note: the og case, ie without setting anything, must also be "yes"
              * The number of questions asked will be proportional to the number of variables in the predicate
          + NP Jargon: Search is reducible to Decision
          + P vs NP is important for cryptography, bc we need to find hard problems for which we know the solution, but an adversary cannot easily (ie in poly time) determine the solution (soft problem)
              * if P = NP, then such problems might not exist

---

<h3>Languages</h3>

  * __F2.2__
      - A language describes the inputs (in this case, predicates) that result in a "yes" confirmation when passed through some ALG'.
      - If something is in a language, the answer is Yes, and if it is not, the answer is No.
      - A "yes" means that the predicate is satisfiable and it is in L.
      - A "no" means that
          + The predicate is not well formed (not in the right format), or
          + The predicate is not satisfiable

---

<h3>One-way funuctions</h3>

  * __F2.3__
      - For such a system, f is public, but knowing f and y does not make it easy to find x

--- 

<h3>Aside: hardness and P vs NP</h3>

  * Algorithms in P and NP are described by their *worst case* performance.
      - Ie, some algs that are in NP are only difficult to solve in degenerate cases (ie exponentially rare cases)
          + some 3-sat sols are poly time in most cases but exponential in exponentially rare cases (these use some randomness)
  * This introduces the ave P vs ave NP problem __F2.4__
      - For things with a sampleable distribution (ie nature), it might be that ave P = ave NP.
          + ie it might be that P != NP, but for whatever we care about, P = NP, and so everything we care about can be easily solved
              * This is probably not the case, but we don't know
          + This would mean that there exist hard problems, but it's just as hard to find them as it would be to solve them.
      - "There exist easy-to-find unsolved hard problems"
      - If ave P != ave NP, then there exist problems that are generally hard to solve and they are not that hard to find
      - For more infor, look at Luca Trevisan explanation of ave P vs ave NP
  * For cryptography, we will assume that there exist 1-way functions
      - & there exist hard "solved" problems

---

<h3>Back to One way functions</h3>

  * __F2.5__
  * If a challenger uses a one-way function to generate some Y, and the adversary responds with some x', it is very, very unlikely that f(x')=Y.
      - If it does, the adversary wins

---

<h3>Machines for Languages</h3>

  * Randomized Poly-Time (RP) Machines
  * __F2.6__
      - For some machine M with language L,
      - if x is in the language, it returns Yes with a greater than 2/3 probability.
      - If x is not in the language, it always returns No.
      - If a machine says Yes, you know that x is definitely in L
          + you can label this input as being in L
      - If it says No, you have no way to tell
          + you can repeat this a bunch of times, and if even once it says yes, you label the input as being in L
          + If not, we grow more confident that x is not in L.
      - Intuitively, if we repeat the experiment k times, how much confidence can we get that x is/isn't in L?
          + Homework Question
  * Co-RP & BPP
      - __F2.7__
      - For Co-RP, it is like the inverse of RP
          + No error if obj is in the language
          + some error if obj is not in the language
      - BPP: Bounded (away from 1/2) Probabalistic Poly-Time
          + If you amplify this (ie run it multiple times) you can use a simple majority to decide if the answer should be yes or no
  * Chernoff Bound
      - __F2.8__
          + With beta = 1/2, we have that the probability that the machine makes a mistake many trials is e<sup>-n/24</sup>, so if we do 24n trials, the probability is degenerate to e<sup>-n</sup> 
      - This concept is important, so you should look into this