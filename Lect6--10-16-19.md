<h1>Lecture 6</h1>

---

<h5>Perceptron</h5>
  * learning by making mistakes
  * If the data is separable, the perceptron can always find the separation within a finite number of mistakes

<h5>Variants of the perceptron</h5>

  * using on a finite dataset
  * Voting and averaging
  * Margin perception

><h5></h5> 