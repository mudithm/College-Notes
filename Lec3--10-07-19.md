<h1>Lecture 3</h1>

---

<h5>Tokenization/Scanning/Lexing</h5>

  * Outputs a series of tokens or lexemes

<h5>Parsing</h5>

  * Takes a list of tokens/lexemes
  * outputs a parse tree
      - tree that represents the syntactic structure or the input
      - We can tell a parser what to do by passing it a grammar

<h5>Context-free Grammar</h5>

  * has a bunch of rules
  * each rule specifies a possible node (internal) in a parse tree
  * Formally, a grammar consists of
      1. a finite set of _tokens_ (terminal symbols)
      2. a finite set of _labels_ for internal nodes (non-terminal symbol)
      3. a finite set of _rules_ 
        * LHS: non-terminal symbol
        * RHS: finite sequence of symbols (_possibly empty_)
            - empty sequence represented by epsilon
      4. Start symbol, a non-terminal
  * We can consider a grammar valid if a valid parse tree can be created from it
  * At each step of parsing, we replace one non-terminal symbol with the RHS of its matching rule

---

<h5>Trouble with grammars</h5>

  1. non-terminal is _defined_(on the LHS of a rule) but not _used_ (on the RHS of a rule, or as a start symbol)
    * This is a useless rule (so long as it is not a start symbol)
  2. non-terminal is _used_ but not _defined_
    * kind of like calling a function that isn't defined anywhere. The code compiles, but will result in a runtime error
  3. Useless rules
  4. Extra constraints not captured by the grammar
    * English ex:
        - `nonterminals`: `{S, NP, VP}` 
        - `terminals`: `{., N, Adj, V, Adv}`
        - `start symbol`: `s`
        - Rules:
            + `S -> NP VP.` 
            + `NP -> N` 
            + `NP -> Adj N`
            + `VP -> V`
            + `VP -> VP Adv` 
        - This grammar doesn't accurately describe the language (allows `Fido walk` and `Dogs sleeps soundly`
        - Need to account for singular/plural nouns/verbs)
        - `nonterminals`: `{S, PNP, SNP, PVP, SVP}` 
        - `terminals`: `{., PN, SN, Adj, PV, SV, Adv}`
        - `start symbol`: `s`
        - New Rules:
            + `S -> SNP SVP.` 
            + `SNP -> SN` 
            + `SNP -> Adj SN`
            + `SVP -> SV`
            + `SVP -> SVP Adv` 
            + `PNP -> PN` 
            + `PNP -> Adj PN`
            + `PVP -> PV`
            + `PVP -> PVP Adv` 
        - Notice that adding just one binary attribute (plural vs singular) complicated the grammar immensely
        - This is why programming language grammars don't take care of _all_ the constraints in the language, but rather use the functionality that it does well and handle the constraints in other ways
            + ie scope, type checking
    * Examples: scope, type checking
    * In C, typedef is also an escape from context-free grammars -- it adds keywords to the grammar
  4b. Too much detail in your grammar
  5. Ambiguous grammar
    * Grammar that lets you parse the same sentence in 2 or more different ways
        - ie improper order of operations, etc  

---

<h5>Aside -- Tokenization / parsing / compilation approach</h5>

Software tools approach

```c
int main(void) { return ! getchar()};
// First, runs through preprocessor, taking care of #include, etc
// Then, runs through the tokenizer, reulting in  
INT | ID (main) | ( | VOID | ) | ; | INT | ID (getchar) | ( | ) | ; | }

//then, passes through the parser, which returns a parse tree 
// if parsed correctly, the leaves of the parse tree will match the 
// tokens of the original code

// then, checking (type checking, scope checking, etc) This is much
// easier to do with a parse tree

// then, intermediate code generation
main:
    push getchar
    call
    .
    .
    .
    ret

// then target code generation
main: 
    call getchar
    tstl %eax, %eax
    setz %al
    ret
// or something like that

// then, run through an assembler, translating assembly into object
// w/ machine code

// then goes to the linker, to replace calls with mem addresses and 
// returns resolved machine code

// Then, kernel can run it
```
>Software tools approach is beneficial in that it allows for divide-and-conquer compiler development, but it makes it difficult to debug since you have to backtrack through all the stages to identify problems
Developed at Bell Labs

The other approach is the IDE approach (ie XeroxPARC SmallTalk)

---

