<h1>Seminar 7: Introduciton to Computer Architecture</h1>


Speaker: Glenn Reinman

<h6>Computers</h6>

  * What is a computer?
      - A programmable device...

<h6>Early Computers</h6>

  * ENIAC (350 Flops)
  * SSEM
  * EDSAC
  * Supercomputers:
      - Cray-1: reached 80 MFlops in 1985

<h6>Growth of Compute Power</h6>

  * Cray 2 was similar to an old iphone.

**Relentless Scaling:** performance of all comuting devices has been increasing exponentially

<h6>Modern Supercomputers</h6>

  * Sunway TaihuLight
      - 125 Petaflops (theoretical peak)
      - Linpack: 93 Petaflops
      - 15 MW

<h6>Exascale Computing</h6>

  * An insatiable need for computieng
      - We need the increasingly growing computing power for complex tasks (weather prediction, genomic analysis, etc)

<h6>Forces that Evolve Computers</h6>

  * Applications. OS, Compiler
  * Instruction Set Architecture
  * Machine Organization
  * Physical Design

<h6>Examples of future Physical Design Issues</h6>

  * Scaling Concerns
      - Power (too much heat)
      - Wire Latency
      - Transistor Variability
  * Interconnect
      - Reduced Latency
      - Increased Bandwidth
  * Silicon Alternatives
      - Quantum Computing
      - DNA Computing

<h6>Area</h6>

>"doubling of transistor density on a manufatured die every 2 years."

There will eventually be a point where the benefit of scaling down is not as extreme, or nonexistent.

<h6>Frequency</h6>

  * Clock Frequency has sort of peaked in recent years
  * THe main reason for this is excess heat

<h6>Power</h6>

  * What is Power?
      - There is a meme

Pushing frequency alone would increase heat at an untenable rate. (would reach the temp of a nuclear reactor relatively soon)

The solution became to split computing into smaller cores that work together

<h6>Dark Silicon</h6>

At some point, heat limitations will cause the design of processors to change.

  * one way is through dark silicon, which means only activating a small part of the cpu at any given time
  * This would lead to chips with different specializied regions that are only activated for specific tasks, and the architecture would switch between regions to maximize efficiency

<h6>Big Data</h6> 

The 4 Vs of Big Data

1. This is a thing
2. THis is another thing
3. This is a third thing
4. This is a fourth thing

<h6>Computaional Demand</h6>

Recognition    ===>    Mining    ===>     Synthesis


<h6>Internet of Things</h6>

  * We need speciality to maintain many functions in a power efficient manner


---

---

<h6>General Purpose Computers</h6>

  * Most personal computers fit this category
  * GPUs have general purpose capability, but also have specialis=zed hardware for certain tasks
      - rasterization
      - texture mapping
      - tihngs
  * A CPU is general purpose, and an ASIC is designed for one particular task.
  * ASIC: Application-Spcecific Integrated Circuit
  * FPGA: Field Programming Gate Array
      - Programmiable logic blocks that can duplicate the functionality of combinatorial functions
      - Range of Functions:
          + microcontroller
          + Programmable ALU
          + Entire "soft" core


<h6>Chip Heterogeneous Platform (CHP)</h6>

SoA -- Sea of Applications

Making as many accelerator models as possible so that we can maximize power efficiency without losing all the flexibility we enjoy.

<h6>Personalized Medicine</h6>

Computational Genomics: Better than Moore's Law

Becomes a big data problem, since the genome sequencing cost is falling faster than computing power can increase.

The goal is to try to sequence a genome in under an hour.

<h6>Brain-Inspired Computing?</h6>

  * Human Brain vs COmputer
      - Power
          + Brain -- 20W
          + Watson -- 85k W
      - Volume of Cooling
          + Brain -- 10%
          + Watson -- 99%

Neurons: they are p cool



